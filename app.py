import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import networkx as nx
import requests
import json
import openai
from google import genai

from streamlit_plotly_events import plotly_events

# ----------------------------------------------------------------------
# ì„¤ì •
# ----------------------------------------------------------------------
# ì£¼ì˜: API í‚¤ë¥¼ ì½”ë“œì— ì§ì ‘ í•˜ë“œì½”ë”©í•˜ëŠ” ê²ƒì€ ë³´ì•ˆìƒ ìœ„í—˜í•©ë‹ˆë‹¤.
# ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œëŠ” st.secrets ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
GEMINI_API_KEY = st.secrets.get("GEMINI_ApI_KEY") 
SERPER_API_KEY = st.secrets.get("SERPER_ApI_KEY")
FILE_NAME = "í‚¤ì›Œë“œ_ìµœì¢…_ì¢…í•©íŠ¸ë Œë“œ_ê°•í™”ë¡œì§.csv"

CLASSIFICATION_CRITERIA = ["ì ‘ê·¼ë°©ì‹ ê¸°ì¤€", "ê±´ì¶•ì„¤ê³„ë‹¨ê³„", "ê³µê°„ì  ìŠ¤ì¼€ì¼"]
COLOR_BASE_COLUMN = "ì ‘ê·¼ë°©ì‹ ê¸°ì¤€"
SIZE_COLUMN = "Final Trend Index" # ë²„ë¸” í¬ê¸° ê¸°ì¤€ ì»¬ëŸ¼
ACADEMIC_COL = "Academic_Total"
MEDIA_COL = "Media_TotalY"

FIXED_COLOR_MAP = {
    "ì‚¬ìš©ì": "#FFD700",
    "ìŠ¤ë§ˆíŠ¸ ê¸°ìˆ ": "#1E90FF",
    "ê³µê°„ êµ¬ì„±": "#FF8C00",
    "ì§€ì†ê°€ëŠ¥ì„±": "#3CB371",
    "ê±´ì¶• ê¸°ìˆ ": "#808080",
    "ë¸Œëœë“œ & ì„œë¹„ìŠ¤": "#9932CC",
    "ëª¨ë“ˆëŸ¬": "#CCCCCC"
}

# ----------------------------------------------------------------------
# ë°ì´í„°
# ----------------------------------------------------------------------
@st.cache_data
def load_data():
    df = pd.read_csv(FILE_NAME, encoding="utf-8-sig")
    for c in [SIZE_COLUMN, ACADEMIC_COL, MEDIA_COL]:
        df[c] = pd.to_numeric(df[c], errors="coerce").fillna(0).astype(int)
    for c in CLASSIFICATION_CRITERIA:
        if c not in df.columns:
            df[c] = "N/A"
        else:
            df[c] = df[c].fillna("N/A")
    if "Keyword" not in df.columns:
        raise ValueError("CSVì— 'Keyword' ì¹¼ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    return df

df = load_data()

# ----------------------------------------------------------------------
# LLM (Gemini) ì •ì˜ ìƒì„±
# ----------------------------------------------------------------------
def generate_definition_with_llm(keyword, _log_cb=lambda x: None):
    """
    1. ì •ì˜: Gemini APIë¡œ ìƒì„± (ì‹¤ì œ Google GenAI API í˜¸ì¶œ).
    """
    if not GEMINI_API_KEY: # âœ¨ ìˆ˜ì •
        msg = "[ì˜¤ë¥˜] GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤." # âœ¨ ìˆ˜ì •
        return msg

    try:
        client = genai.Client(api_key=GEMINI_API_KEY) # âœ¨ ìˆ˜ì •: Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”

        system_prompt = (
            "ë‹¹ì‹ ì€ ê±´ì¶•, ë„ì‹œ, ê³µê°„ ë””ìì¸ ë¶„ì•¼ì˜ ìµœì‹  íŠ¸ë Œë“œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
            "ì‚¬ìš©ìê°€ ì œì‹œí•œ í‚¤ì›Œë“œì— ëŒ€í•´ ëª…í™•í•˜ê³  ê°„ê²°í•˜ë©° ì „ë¬¸ì ì¸ ì •ì˜ë¥¼ í•œêµ­ì–´ë¡œ 3~5ë¬¸ì¥ ì´ë‚´ë¡œ ì‘ì„±í•˜ì„¸ìš”."
        )
        user_prompt = f"í‚¤ì›Œë“œ '{keyword}'ì— ëŒ€í•œ ì •ì˜ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”."

        # response = client.chat.completions.create(...) # ê¸°ì¡´ ì½”ë“œ (ë³µì¡)
        response = client.models.generate_content( # âœ¨ ìˆ˜ì •: generate_content ì‚¬ìš©
            model="gemini-2.5-flash", # âœ¨ ìˆ˜ì •: Gemini ëª¨ë¸ë¡œ ë³€ê²½
            contents=user_prompt,
            config=genai.types.GenerateContentConfig(
                system_instruction=system_prompt, # âœ¨ ìˆ˜ì •: system_instruction ì‚¬ìš©
                temperature=0.3,
                max_output_tokens=300 # max_tokens ëŒ€ì‹  max_output_tokens ì‚¬ìš©
            )
        )
        
        # result = response.choices[0].message.content.strip() # ê¸°ì¡´ ì½”ë“œ
        result = response.text.strip() # âœ¨ ìˆ˜ì •: response.text ì‚¬ìš©

        if not result:
            raise ValueError("LLMì´ ì •ì˜ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            
        return result
        
    # except openai.AuthenticationError: # ê¸°ì¡´ ì½”ë“œ
    except genai.errors.APIError as e: # âœ¨ ìˆ˜ì •: Gemini API ì˜¤ë¥˜ ì²˜ë¦¬
        msg = f"[Gemini API ì˜¤ë¥˜] í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ ìš”ì²­ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”: {e}"
        return msg
    except Exception as e:
        msg = f"[LLM ì²˜ë¦¬ ì˜¤ë¥˜: {e}]"
        return "LLM ì •ì˜ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: " + str(e)
# ----------------------------------------------------------------------
# Serper
# ----------------------------------------------------------------------
def get_serper_info(keyword, search_type, _log_cb=lambda x: None):
    """
    2. ë‰´ìŠ¤: Serper API í™œìš© (ìµœì‹ /ì¸ê¸° ê²€ìƒ‰ ê°•í™”)
    3. ë…¼ë¬¸: Serper API í™œìš© (í•™ìˆ  ê²€ìƒ‰ ê°•í™”)
    """
    url = "https://google.serper.dev/search"
    query, num = "", 5
    tbm_type = None

    if not SERPER_API_KEY:
        msg = "[ì˜¤ë¥˜] SERPER_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
        return msg
    
    if search_type == "definition":
        return "Serperë¥¼ í†µí•œ ì •ì˜ ê²€ìƒ‰ì€ LLMìœ¼ë¡œ ëŒ€ì²´ë˜ì—ˆìŠµë‹ˆë‹¤."
    elif search_type == "news":
        query = f"{keyword} ìµœì‹  íŠ¸ë Œë“œ"
        tbm_type = "news" 
        num = 10 
    elif search_type == "scholar":
        query = f"{keyword} í•™ìˆ  ë…¼ë¬¸"
        num = 10 
    else:
        return "ì§€ì›í•˜ì§€ ì•ŠëŠ” search_type"

    headers = {"X-API-KEY": SERPER_API_KEY, "Content-Type": "application/json"}
    payload = {"q": query, "hl": "ko", "num": num}
    if tbm_type:
        payload["tbm"] = tbm_type

    try:
        r = requests.post(url, headers=headers, data=json.dumps(payload), timeout=20)
        r.raise_for_status()
        data = r.json()

        key = "news" if search_type == "news" else "organic"
        items = data.get(key, []) or []
        
        if search_type == "scholar":
            def is_scholar(item):
                title = item.get("title", "").lower()
                link = item.get("link", "").lower()
                return (
                    "ë…¼ë¬¸" in title or "ì—°êµ¬" in title or "ì €ë„" in title or 
                    "scholar.google" in link or "doi.org" in link or "researchgate" in link
                )
            items = [it for it in items if is_scholar(it)]
            
        results = [{"title": it.get("title", "(ì œëª© ì—†ìŒ)"), "link": it.get("link", "#")} for it in items[:5]]
        
        if not results and search_type in ["news", "scholar"]:
            payload.pop("tbm", None) 
            payload["num"] = 5
            
            if search_type == "scholar":
                payload["q"] = f"{keyword} í•™ìˆ  ë…¼ë¬¸" 
            else: 
                payload["q"] = f"{keyword} ìµœì‹  íŠ¸ë Œë“œ"
                
            r_fallback = requests.post(url, headers=headers, data=json.dumps(payload), timeout=20)
            r_fallback.raise_for_status()
            data_fallback = r_fallback.json()
            items_fallback = data_fallback.get("organic", [])
            
            if search_type == "scholar":
                 items_fallback = [it for it in items_fallback if is_scholar(it)]
                 
            results = [{"title": it.get("title", "(ì œëª© ì—†ìŒ)"), "link": it.get("link", "#")} for it in items_fallback[:5]]

        return results

    except requests.exceptions.RequestException as e:
        status = getattr(e.response, "status_code", "N/A")
        msg = f"[Serper API ì˜¤ë¥˜: status={status}, {e}]"
        return msg
    except Exception as e:
        msg = f"[ì²˜ë¦¬ ì˜¤ë¥˜: {e}]"
        return msg

# ----------------------------------------------------------------------
# ê·¸ë˜í”„ (íˆíŠ¸ë°•ìŠ¤ + ì‹œê° ë ˆì´ì–´) - ì• ë‹ˆë©”ì´ì…˜ ìµœì í™” (3ê°œ Trace)
# ----------------------------------------------------------------------
def create_keyword_figure(df, classification_criteria, size_criteria, color_base_column):
    G = nx.Graph()

    for _, row in df.iterrows():
        kw = str(row["Keyword"])
        G.add_node(
            kw,
            size=float(row[size_criteria]),
            group=str(row[classification_criteria]),
            color_group=str(row[color_base_column]),
        )

    for group_name, group_df in df.groupby(classification_criteria):
        group_keywords = group_df["Keyword"].astype(str).tolist()
        if len(group_keywords) > 1:
            leader_row = group_df.loc[group_df[size_criteria].idxmax()]
            leader = str(leader_row["Keyword"])
            for kw in group_keywords:
                if kw != leader:
                    G.add_edge(leader, kw)

    # k=0.55 -> k=0.8ë¡œ ì¦ê°€ì‹œì¼œ ë…¸ë“œ ê°„ê²©ì„ ë„“í˜
    pos = nx.spring_layout(G, seed=42, k=0.8, iterations=60)
    
    all_nodes_sorted = sorted(G.nodes())

    # 1. ì—£ì§€ Trace
    edge_x, edge_y = [], []
    for a, b in G.edges():
        x0, y0 = pos[a]
        x1, y1 = pos[b]
        edge_x += [x0, x1, None]
        edge_y += [y0, y1, None]

    edge_trace = go.Scatter(
        x=edge_x, 
        y=edge_y,
        mode="lines",
        line=dict(width=0.5, color="rgba(150,150,160,0.25)"),
        hoverinfo="skip",
        showlegend=False
    )
    traces = [edge_trace]

    # 2. ë…¸ë“œ ë°ì´í„° í†µí•©
    all_xs, all_ys, all_sizes, all_texts, all_colors, all_customdata, all_hovertext = [], [], [], [], [], [], []
    node_sizes_all = [G.nodes[n]["size"] for n in G.nodes()]
    sizeref = 2.0 * max(node_sizes_all) / (80.0 ** 2) if node_sizes_all else 1

    for kw in all_nodes_sorted:
        node_data = G.nodes[kw]
        
        all_xs.append(pos[kw][0])
        all_ys.append(pos[kw][1])
        all_sizes.append(max(10.0, node_data["size"]))
        all_texts.append(kw)
        all_colors.append(FIXED_COLOR_MAP.get(node_data["color_group"], "#CCCCCC"))
        all_customdata.append(kw) 
        all_hovertext.append(f"í‚¤ì›Œë“œ: {kw}<br>ê·¸ë£¹: {node_data['group']}<br>í¬ê¸°: {int(node_data['size'])}")

    # 3. ë§ˆì»¤ ë ˆì´ì–´ (ë²„ë¸”)
    marker_trace = go.Scatter(
        x=all_xs, y=all_ys,
        mode="markers",
        hoverinfo="text",
        hovertext=all_hovertext,
        marker=dict(
            size=all_sizes,
            sizemode="area",
            sizeref=sizeref,
            sizemin=10,
            color=all_colors,
            line=dict(width=1, color="rgba(20,20,20,0.6)"),
            opacity=0.95,
        ),
        showlegend=False, 
        name="Markers",
        customdata=all_customdata, 
    )
    traces.append(marker_trace)
    
    # 4. í…ìŠ¤íŠ¸ ë ˆì´ì–´ (í‚¤ì›Œë“œ ì´ë¦„)
    text_trace = go.Scatter(
        x=all_xs, y=all_ys,
        mode="text",
        text=all_texts,
        textposition="middle center",
        textfont=dict(size=10, color="black"),
        hoverinfo="skip", 
        showlegend=False,
        name="Text",
        customdata=all_customdata, 
    )
    traces.append(text_trace)

    # 5. íˆíŠ¸ë°•ìŠ¤ ë ˆì´ì–´ (í´ë¦­ ì˜ì—­)
    all_hit_sizes = [s * 1.6 + 20 for s in all_sizes]
    hit_trace = go.Scatter(
        x=all_xs, y=all_ys,
        mode="markers",
        marker=dict(
            size=all_hit_sizes,
            sizemode="area",
            sizeref=sizeref,
            sizemin=20,
            color="rgba(0,0,0,0.01)", 
            line=dict(width=0),
        ),
        hoverinfo="skip",
        showlegend=False,
        name="Hitbox",
        customdata=all_customdata 
    )
    traces.append(hit_trace)
    
    # 6. Figure Layout ì„¤ì • (Transition í¬í•¨)
    fig = go.Figure(
        data=traces,
        layout=go.Layout(
            title=dict(
                text=f"í‚¤ì›Œë“œ ë„¤íŠ¸ì›Œí¬ (ê·¸ë£¹: {classification_criteria}, ìƒ‰ìƒ: {color_base_column})",
                font=dict(size=18),
            ),
            margin=dict(b=20, l=5, t=50, r=150), 
            
            annotations=[
                dict(
                    xref='paper', yref='paper',
                    x=1.02, y=0.98 - i*0.04,
                    text=f'<span style="color:{FIXED_COLOR_MAP[group]}; font-size:12px;">\u25CF</span> {group}',
                    showarrow=False,
                    align="left",
                    visible=group in df[color_base_column].unique() 
                ) for i, group in enumerate(FIXED_COLOR_MAP.keys())
            ],
            showlegend=False, 
            hovermode="closest",
            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
            clickmode="event+select",
            dragmode="pan",
            transition=dict(
                duration=700, 
                easing="cubic-in-out" 
            )
        ),
    )
    return fig

# ----------------------------------------------------------------------
# ì´ë²¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ë³µì› (ê°€ì¥ ê²¬ê³ í•˜ê²Œ)
# (ë³€ë™ ì—†ìŒ)
# ----------------------------------------------------------------------
def extract_keyword_from_events(events, fig: go.Figure):
    if not events or not isinstance(events, list):
        return None, None
    ev = events[0] or {}
    # 1) customdata ì§ì ‘
    cd = ev.get("customdata", None)
    if isinstance(cd, list):
        if cd:
            return cd[0], ev
    elif isinstance(cd, str):
        return cd, ev
    # 2) curveNumber/pointNumberë¡œ fig.dataì—ì„œ ì—­ì°¸ì¡°
    curve = ev.get("curveNumber", None)
    pnum = ev.get("pointNumber", ev.get("pointIndex", None))
    try:
        if curve is not None and pnum is not None:
            trace = fig.data[int(curve)]
            # ìš°ì„  customdata â†’ ì—†ìœ¼ë©´ text
            if hasattr(trace, "customdata") and trace.customdata is not None:
                val = trace.customdata[int(pnum)]
                if isinstance(val, (str, int, float)):
                    return str(val), ev
                elif isinstance(val, (list, tuple)) and len(val) > 0:
                    return str(val[0]), ev
            if hasattr(trace, "text") and trace.text is not None:
                txt = trace.text[int(pnum)]
                if isinstance(txt, (str, int, float)):
                    return str(txt), ev
    except Exception:
        pass
    # 3) ìµœí›„: trace ì´ë¦„(ë¶€ì •í™• ê°€ëŠ¥)
    if curve is not None:
        try:
            name = fig.data[int(curve)].name
            return str(name), ev
        except Exception:
            pass
    return None, ev

# ----------------------------------------------------------------------
# ì•±
# ----------------------------------------------------------------------
def run():
    st.set_page_config(layout="wide", page_title="í‚¤ì›Œë“œ íŠ¸ë Œë“œ ì‹œê°í™”")
    st.title("ğŸ“Š í‚¤ì›Œë“œ ë¶„ì„ ë° ì‹œê°í™”")
    st.caption("ê·¸ë˜í”„ì—ì„œ **í‚¤ì›Œë“œ**ë¥¼ í´ë¦­í•˜ë©´ ì•„ë˜ì— ì •ì˜/ë‰´ìŠ¤/ë…¼ë¬¸ì´ í‘œì‹œë©ë‹ˆë‹¤.")

    # í‚¤ì›Œë“œ/API ì„¤ì • ê°€ì´ë“œ (í•˜ë“œì½”ë”©ëœ í‚¤ì˜ ê²½ìš° ê²½ê³ ëŠ” ìœ ì§€)
    if not GEMINI_API_KEY or not SERPER_API_KEY:
        st.error("âš ï¸ **API í‚¤ ì„¤ì • í•„ìš”:** GEMINI_API_KEY ë˜ëŠ” SERPER_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    with st.sidebar:
        st.header("ğŸ” ë¶„ë¥˜ ê¸°ì¤€")
        crit = st.radio("ê·¸ë£¹í•‘ ê¸°ì¤€", CLASSIFICATION_CRITERIA, index=0)

        # ====== ì¶”ê°€ëœ íŒì—… ë²„íŠ¼ ë¡œì§ ======
        st.markdown("---")
        with st.popover("í‚¤ì›Œë“œ ë²„ë¸” í¬ê¸° ê¸°ì¤€"):
            st.markdown(f"**ë²„ë¸” í¬ê¸° ê¸°ì¤€:**")
            st.markdown(f"í‚¤ì›Œë“œ ë²„ë¸”ì˜ í¬ê¸°ëŠ” **'{SIZE_COLUMN}'** ê°’ì— ë¹„ë¡€í•˜ì—¬ ì„¤ì •ë©ë‹ˆë‹¤.")
            st.markdown(f"ì´ëŠ” í•™ìˆ  ì—°êµ¬ ë° ë¯¸ë””ì–´ ë…¸ì¶œë„ë¥¼ ì¢…í•©í•œ **ìµœì¢… íŠ¸ë Œë“œ ì§€ìˆ˜**ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.")
            st.markdown(f"**A. íŠ¸ë Œë“œ ì ìˆ˜** = ëŒ€ì¤‘ì˜ ê´€ì‹¬ë„ ë° ë¯¸ë˜ ì„±ì¥ì„¸ í‰ê°€. Google Trendsë¥¼ ì‚¬ìš©í•˜ë©°, ìµœê·¼ ê²€ìƒ‰ëŸ‰ì´ ì´ì „ë³´ë‹¤ ì–¼ë§ˆë‚˜ í­ë°œì ìœ¼ë¡œ ëŠ˜ì—ˆê³ (ì„±ì¥ë¥ ), ê·¸ ìƒìŠ¹ì„¸ê°€ ì–¼ë§ˆë‚˜ ê°€íŒŒë¥´ê²Œ ìœ ì§€ë˜ëŠ”ì§€(ëª¨ë©˜í…€)ë¥¼ ë´…ë‹ˆë‹¤. / ì„±ì¥ë¥  (70%) + ëª¨ë©˜í…€ (30%)")
            st.markdown(f"**B. ë¯¸ë””ì–´ ì ìˆ˜** = ëŒ€ì¤‘ ë§¤ì²´ë¥¼ í†µí•œ í™•ì‚° ì •ë„ í‰ê°€. ë‰´ìŠ¤/ê¸°ì‚¬ ê±´ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë©°, ìµœê·¼ 1ê°œì›”ê°„ì˜ ê¸°ì‚¬ ì¦ê°€ì„¸(ì„±ì¥ë¥ )ì™€ ì „ì²´ 1ë…„ê°„ì˜ ê¸°ì‚¬ ê·œëª¨(ì´ëŸ‰)ë¥¼ ë´…ë‹ˆë‹¤. / ì„±ì¥ë¥  (60%) + ì´ëŸ‰ (40%)")
            st.markdown(f"**C. í•™ìˆ  ì ìˆ˜** = ìµœê·¼ 3ë…„ê°„ì˜ ë…¼ë¬¸ ê±´ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë©°, í•´ë‹¹ ê¸°ê°„ì˜ ì—°êµ¬ ì¦ê°€ ì†ë„(ì„±ì¥ë¥ )ì™€ ì „ì²´ ì—°êµ¬ëŸ‰(ì´ëŸ‰)ì„ ë´…ë‹ˆë‹¤. / ì„±ì¥ë¥  (60%) + ì´ëŸ‰ (40%)")
            st.markdown(f"ì„¸ ì ìˆ˜ê°€ ì‚°ì •ë˜ë©´, ì•„ë˜ì˜ ê³µì‹ì— ë”°ë¼ ìµœì¢… íŠ¸ë Œë“œ ì§€ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.")
            st.markdown(f"**ìµœì¢…Â íŠ¸ë Œë“œÂ ì§€ìˆ˜=(0.5Ã—íŠ¸ë Œë“œÂ ì ìˆ˜)+(0.25Ã—ë¯¸ë””ì–´Â ì ìˆ˜)+(0.25Ã—í•™ìˆ Â ì ìˆ˜)**")


        # ==================================

    fig = create_keyword_figure(df.copy(), crit, SIZE_COLUMN, COLOR_BASE_COLUMN)

    events = plotly_events(
        fig,
        click_event=True,
        select_event=True,
        hover_event=False,
        override_height=720,
        override_width=1100,
        key="interactive_graph_robust",
    )

    # (ë””ë²„ê·¸) ì›ì‹œ ì´ë²¤íŠ¸
    #with st.expander("ğŸ›  ì´ë²¤íŠ¸ ì›ì‹œ ë¡œê·¸ (ë””ë²„ê·¸)"):
        #st.write(events)

    # í‚¤ì›Œë“œ ë³µì›
    clicked_keyword, ev_used = extract_keyword_from_events(events, fig)

    result_area = st.container()
    if clicked_keyword:
        with result_area:
            st.markdown("---")
            st.subheader(f"ğŸ” ì„ íƒ í‚¤ì›Œë“œ: **{clicked_keyword}**")
            
            null_log = lambda x: None 
            
            with st.spinner("ê²€ìƒ‰ ë° ì •ì˜ ìƒì„± ì¤‘ì…ë‹ˆë‹¤â€¦"):
                definition = generate_definition_with_llm(clicked_keyword, _log_cb=null_log)
                news = get_serper_info(clicked_keyword, "news", _log_cb=null_log)
                scholar = get_serper_info(clicked_keyword, "scholar", _log_cb=null_log)

            is_error = "[ì˜¤ë¥˜]" in definition or "[Serper API ì˜¤ë¥˜]" in str(news) or "[Serper API ì˜¤ë¥˜]" in str(scholar)
            if is_error:
                 st.error("ì¼ë¶€ ê¸°ëŠ¥ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. í‚¤ ì„¤ì • ë° API ì‘ë‹µì„ í™•ì¸í•˜ì„¸ìš”.")
            else:
                 st.success("ê²€ìƒ‰ ë° ì •ì˜ ìƒì„± ì™„ë£Œ")

            t1, t2, t3 = st.tabs(["ì •ì˜ (Chat GPT)", "ìµœì‹ /ì¸ê¸° ë‰´ìŠ¤", "í•™ìˆ  ë…¼ë¬¸"])
            with t1:
                st.markdown(f"**Chat GPT ìƒì„± ì •ì˜**\n\n> {definition}")
            with t2:
                if isinstance(news, list) and news and not is_error:
                    for it in news:
                        st.markdown(f"- [{it['title']}]({it['link']})")
                else:
                    st.warning("ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í‚¤ì›Œë“œë‚˜ API ì‘ë‹µì„ í™•ì¸í•˜ì„¸ìš”.")
            with t3:
                if isinstance(scholar, list) and scholar and not is_error:
                    for it in scholar:
                        st.markdown(f"- [{it['title']}]({it['link']})")
                else:
                    st.warning("ë…¼ë¬¸ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í‚¤ì›Œë“œë‚˜ API ì‘ë‹µì„ í™•ì¸í•˜ì„¸ìš”.")
    else:
        with result_area:
            st.info("ê·¸ë˜í”„ì—ì„œ í‚¤ì›Œë“œë¥¼ í´ë¦­í•´ ì£¼ì„¸ìš”.")

if __name__ == "__main__":

    run()

